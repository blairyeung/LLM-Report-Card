{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from core.config import *\n",
    "from tqdm import tqdm, trange\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "# batched using threads\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reader utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(file_path):\n",
    "    with jsonlines.open(file_path) as reader:\n",
    "        data = [obj for obj in reader]\n",
    "    return data\n",
    "\n",
    "def get_datasets(meta, topic, base='Mistral-7B-Instruct-v0.2'):\n",
    "    if meta == 'mmlu':\n",
    "        train_path = f'datasets/mmlu/{topic}/{base}-train.jsonl'\n",
    "        test_path = f'datasets/mmlu/{topic}/{base}-test.jsonl'\n",
    "\n",
    "        train_ds, test_ds = read_jsonl(train_path), read_jsonl(test_path)\n",
    "\n",
    "    elif meta == 'anthropic':\n",
    "        train_path = f'datasets/anthropic-eval/{topic}/{base}-train.jsonl'\n",
    "        test_path = f'datasets/anthropic-eval/{topic}/{base}-test.jsonl'\n",
    "\n",
    "        train_ds, test_ds = read_jsonl(train_path), read_jsonl(test_path)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown meta: {meta}\")\n",
    "\n",
    "    return train_ds, test_ds\n",
    "\n",
    "no_to_letter = {0: 'A', 1: 'B', 2: 'C', 3: 'D'} #  0-3: A-D, ALL OTHERS: N\n",
    "\n",
    "def format_single_entry_mmlu(entry):\n",
    "    q, choice = entry['question'], entry['choices']\n",
    "\n",
    "    choice_str = '\\n'.join([f'{no_to_letter[i]}: {c}' for i, c in enumerate(choice)])\n",
    "\n",
    "    return f'Question: {q}\\nChoices:\\n{choice_str}'\n",
    "\n",
    "def format_single_entry_anthropic(entry):\n",
    "    q = entry['question']\n",
    "    return q\n",
    "\n",
    "def get_embedding_strs(ds, meta):\n",
    "    if meta == 'mmlu':\n",
    "        return [format_single_entry_mmlu(entry) for entry in ds]\n",
    "    elif meta == 'anthropic':\n",
    "        return [format_single_entry_anthropic(entry) for entry in ds]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown meta: {meta}\")\n",
    "    \n",
    "def preprocess_ds(meta, topic, base='Mistral-7B-Instruct-v0.2'):\n",
    "    train_ds, test_ds = get_datasets(meta, topic, base)\n",
    "    train_strs, test_strs = get_embedding_strs(train_ds, meta), get_embedding_strs(test_ds, meta)\n",
    "    return train_strs, test_strs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_jsonl(questions, emb):\n",
    "    return [{'question': q, 'embedding': e} for q, e in zip(questions, emb)]\n",
    "\n",
    "def save_jsonl(file_path, file_content):\n",
    "    with jsonlines.open(file_path, 'w') as writer:\n",
    "        for line in file_content:\n",
    "            writer.write(line)\n",
    "    return file_path\n",
    "\n",
    "def save_npz(file_path, file_content):\n",
    "    np.savez(file_path, file_content)\n",
    "    return file_path\n",
    "\n",
    "def save_embeddings(train_emb, test_emb, meta, topic, format='npz'):\n",
    "    if meta == 'mmlu':\n",
    "        train_path = f'datasets/mmlu/{topic}/embedding-train.jsonl'\n",
    "        test_path = f'datasets/mmlu/{topic}/embedding-test.jsonl'\n",
    "\n",
    "    elif meta == 'anthropic':\n",
    "        train_path = f'datasets/anthropic-eval/{topic}/embedding-train.jsonl'\n",
    "        test_path = f'datasets/anthropic-eval/{topic}/embedding-test.jsonl'\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown meta: {meta}\")\n",
    "\n",
    "    if format == 'npz':\n",
    "        train_path = train_path.replace('.jsonl', '.npz')\n",
    "        test_path = test_path.replace('.jsonl', '.npz')\n",
    "        save_npz(train_path, train_emb)\n",
    "        save_npz(test_path, test_emb)\n",
    "\n",
    "    elif format == 'jsonl':\n",
    "        save_jsonl(train_path, train_emb)\n",
    "        save_jsonl(test_path, test_emb)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown format: {format}\")\n",
    "    \n",
    "    print(f\"Saved embeddings to {train_path} and {test_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-large\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    emb = client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "    del client\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_embedding(texts, model=\"text-embedding-3-large\"):\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        embeddings = list(executor.map(lambda x: get_embedding(x, model), texts))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tsne\n",
    "\n",
    "def plot_tsne(embeddings, labels, topic, meta):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    # use blues \n",
    "    cmap = plt.cm.get_cmap('Blues', 4)\n",
    "\n",
    "    # label = 0 train label = 1 test, plot using different color (blue, orange)\n",
    "    for i in range(2):\n",
    "        indices = np.where(labels == i)\n",
    "        plt.scatter(embeddings_2d[indices, 0], embeddings_2d[indices, 1], c=cmap(i), label=f'{i} set', s=10)\n",
    "\n",
    "    # plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=labels, cmap=cmap, s=10)\n",
    "    plt.legend()\n",
    "    plt.title(f't-SNE visualization of {meta} dataset for {topic} topic')\n",
    "    ds_type = 'mmlu' if meta == 'mmlu' else 'anthropic-eval'\n",
    "    path = f'datasets/{ds_type}/{topic}/tsne.jpg'\n",
    "    plt.savefig(path, dpi=600)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = 'mmlu'\n",
    "topics = [# 'machine_learning',\n",
    "          # 'high_school_physics',\n",
    "          # 'high_school_world_history',\n",
    "          # 'high_school_chemistry',\n",
    "          # 'college_biology',\n",
    "          'high_school_mathematics'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_embedding(meta, topic):\n",
    "    train_strs, test_strs = preprocess_ds(meta, topic)\n",
    "    train_emb, test_emb = np.array(batched_embedding(train_strs)), np.array(batched_embedding(test_strs))\n",
    "    save_embeddings(train_emb, test_emb, meta, topic, format='npz')\n",
    "    plot_tsne(np.concatenate([train_emb, test_emb], axis=0), [0]*(len(train_emb)) + [1]*len(test_emb), topic, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in tqdm(topics):\n",
    "    sample_embedding(meta, topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory containing the files\n",
    "directory = 'datasets/openend/_raw/test'  # Current directory. Modify as needed.\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if \"dataset_\" in filename:\n",
    "        # Remove the prefix 'datasets_'\n",
    "        new_filename = filename[len(\"dataset_\"):]\n",
    "        # Construct full old and new file paths\n",
    "        old_file = os.path.join(directory, filename)\n",
    "        new_file = os.path.join(directory, new_filename)\n",
    "        # Rename the file\n",
    "        os.rename(old_file, new_file)\n",
    "        print(f'Renamed \"{filename}\" to \"{new_filename}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
