{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "from openai import OpenAI\n",
    "from config import *\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# batched using threads\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "# sklearn confusion matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "def read_jsonl(file_path):\n",
    "    with jsonlines.open(file_path) as reader:\n",
    "        data = [obj for obj in reader]\n",
    "    return data\n",
    "\n",
    "def read_npz(file_path):\n",
    "    return np.load(file_path)['arr_0']\n",
    "\n",
    "def get_datasets(meta, topic, model='Mistral-7B-Instruct-v0.2'):\n",
    "    if meta == 'mmlu':\n",
    "        train_path = f'datasets/mmlu/{topic}/{model}-train.jsonl'\n",
    "        test_path = f'datasets/mmlu/{topic}/{model}-test.jsonl'\n",
    "\n",
    "        train_emb_path = f'datasets/mmlu/{topic}/embedding-train.npz'\n",
    "        test_emb_path = f'datasets/mmlu/{topic}/embedding-test.npz'\n",
    "\n",
    "        train_ds, test_ds = read_jsonl(train_path), read_jsonl(test_path)\n",
    "        train_emb, test_emb = read_npz(train_emb_path), read_npz(test_emb_path)\n",
    "\n",
    "\n",
    "    elif meta == 'anthropic':\n",
    "        train_path = f'datasets/anthropic-eval/{topic}/{model}-train.jsonl'\n",
    "        test_path = f'datasets/anthropic-eval/{topic}/{model}-test.jsonl'\n",
    "\n",
    "        train_emb_path = f'datasets/anthropic-eval/{topic}/embedding-train.npz'\n",
    "        test_emb_path = f'datasets/anthropic-eval/{topic}/embedding-test.npz'\n",
    "\n",
    "        train_ds, test_ds = read_jsonl(train_path), read_jsonl(test_path)\n",
    "        train_emb, test_emb = read_npz(train_emb_path), read_npz(test_emb_path)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown meta: {meta}\")\n",
    "    \n",
    "    train_ds, test_ds = get_embedding_strs(train_ds, model, meta), get_embedding_strs(test_ds, model, meta)\n",
    "\n",
    "\n",
    "    return train_ds, test_ds, train_emb, test_emb\n",
    "\n",
    "\n",
    "no_to_letter = {0: 'A', 1: 'B', 2: 'C', 3: 'D'} #  0-3: A-D, ALL OTHERS: N\n",
    "\n",
    "def format_single_entry_mmlu(entry, model):\n",
    "    q, choice, gt, ans = entry['question'], entry['choices'], entry['answer'], entry[model]['answer']\n",
    "\n",
    "    choice_str = '\\n'.join([f'{no_to_letter[i]}: {c}' for i, c in enumerate(choice)])\n",
    "\n",
    "    return {'question': f'Question: {q}\\nChoices:\\n{choice_str}', 'correctness' :(gt == ans)}\n",
    "\n",
    "def format_single_entry_anthropic(entry):\n",
    "    q = entry['question']\n",
    "    return q\n",
    "\n",
    "def get_embedding_strs(ds, model, meta):\n",
    "    if meta == 'mmlu':\n",
    "        return [format_single_entry_mmlu(entry, model) for entry in ds]\n",
    "    elif meta == 'anthropic':\n",
    "        return [format_single_entry_anthropic(entry, model) for entry in ds]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown meta: {meta}\")\n",
    "    \n",
    "def preprocess_ds(meta, topic, base='Mistral-7B-Instruct-v0.2'):\n",
    "    train_ds, test_ds = get_datasets(meta, topic, base)\n",
    "    train_strs, test_strs = get_embedding_strs(train_ds, meta), get_embedding_strs(test_ds, meta)\n",
    "    return train_strs, test_strs\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression and plottings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "def logistic_reg(train_emb, train_label):\n",
    "    clf = LogisticRegression(random_state=0, max_iter=1000).fit(train_emb, train_label)\n",
    "    return clf\n",
    "\n",
    "def get_accuracy(clf, test_emb, test_label):\n",
    "    pred = clf.predict(test_emb)\n",
    "    return accuracy_score(test_label, pred)\n",
    "\n",
    "def get_confusion_matrix(clf, test_emb, test_label):\n",
    "    pred = clf.predict(test_emb)\n",
    "    return confusion_matrix(test_label, pred)\n",
    "\n",
    "def evaluate_reg(train_emb, train_label, test_emb, test_label):\n",
    "    clf = logistic_reg(train_emb, train_label)\n",
    "    return get_accuracy(clf, test_emb, test_label)\n",
    "\n",
    "def knn(train_emb, train_label, test_emb, test_label, k=5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(train_emb, train_label)\n",
    "    return get_accuracy(knn, test_emb, test_label)\n",
    "\n",
    "\n",
    "def get_oracle_acc(test_label):\n",
    "    return max(np.mean(test_label), 1 - np.mean(test_label))\n",
    "\n",
    "def plot_tsne(embeddings, labels):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    X_2d = tsne.fit_transform(embeddings)\n",
    "    target_ids = range(len(labels))\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    # use greish aethestically pleasing colors\n",
    "    colors = ['tab:blue', 'tab:orange']\n",
    "    correctness = ['Incorrect', 'Correct']\n",
    "    for i, c in zip(target_ids, colors):\n",
    "        plt.scatter(X_2d[labels == i, 0], X_2d[labels == i, 1], c=c, label=correctness[i])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    # add label text (number) on each block\n",
    "\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    cax = ax.matshow(cm, cmap='Blues')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticklabels([''] + ['F', 'T'])\n",
    "    ax.set_yticklabels([''] + ['F', 'T'])\n",
    "    for (i, j), val in np.ndenumerate(cm):\n",
    "        ax.text(j, i, f'{val}', ha='center', va='center')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix')\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "meta = 'mmlu'\n",
    "topics = ['machine_learning',\n",
    "          'high_school_physics',\n",
    "          'high_school_world_history',\n",
    "          'high_school_chemistry',\n",
    "          'college_biology',\n",
    "          'high_school_mathematics'\n",
    "          ]\n",
    "\n",
    "topic = topics[1]\n",
    "models = [ 'Mistral-7B-Instruct-v0.2',\n",
    "          'Mixtral-8x7B-Instruct-v0.1',\n",
    "          'Llama-2-13b-chat-hf',\n",
    "          'Llama-2-70b-chat-hf',\n",
    "          'gpt-3.5-turbo-1106']"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log reg eval w/ oracle baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Oracle accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "df = pd.DataFrame(columns=['topic', 'model', 'oracle_acc', 'model_acc', 'logistic_reg_acc'])\n",
    "for topic in tqdm(topics):\n",
    "    for model in models:\n",
    "        train_ds, test_ds, train_emb, test_emb = get_datasets(meta, topic, model)\n",
    "        train_labels = np.array([entry['correctness'] for entry in train_ds], dtype=np.int32)\n",
    "        test_labels = np.array([entry['correctness'] for entry in test_ds], dtype=np.int32)\n",
    "\n",
    "        oracle_acc = get_oracle_acc(test_labels)\n",
    "        model_acc = np.mean(test_labels)\n",
    "        logistic_reg_acc = evaluate_reg(train_emb, train_labels, test_emb, test_labels)\n",
    "        knn_acc = knn(train_emb, train_labels, test_emb, test_labels)\n",
    "        df = df.append({'topic': topic, 'model': model, 'oracle_acc': oracle_acc, 'model_acc': model_acc, 'knn_accuracy' :knn_acc, 'logistic_reg_acc': logistic_reg_acc}, ignore_index=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "# save to csv \n",
    "df.to_csv('results.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "# plot_tsne(test_emb, test_labels)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "# plot_confusion_matrix(get_confusion_matrix(logistic_reg(train_emb, train_labels), test_emb, test_labels), ['Incorrect', 'Correct'], normalize=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
