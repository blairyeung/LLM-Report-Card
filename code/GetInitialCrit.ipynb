{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.models import GPTModel\n",
    "import jsonlines, json\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /Users/yangblair/Documents/GitHub/LLM-Eval-NIPS/code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current Directory:\", current_dir)\n",
    "\n",
    "# Change the current working directory to the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "os.chdir(parent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_file(file_path):\n",
    "    data = []\n",
    "    with jsonlines.open(file_path) as reader:\n",
    "        for obj in reader:\n",
    "            data.append(obj)\n",
    "    return '\\n'.join(str(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openendtopics = [\n",
    "         \"Analyzing Financial Reports\"\n",
    "    ]\n",
    "topics = openendtopics\n",
    "\n",
    "meta = 'openend'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt_template = 'Based on some questions in the field of {topic}, you will propose five orthogonal and comprehensive criteria. Your criteria will be used to qualitatively assess the AI systems. Another teacher will write evaluation cards based on these criteria.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef78be466da64e28a6e0b3ee97583766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_criteria = {}\n",
    "for topic in tqdm(topics):\n",
    "    file_path = f'datasets/{meta}/_raw/train/{topic}.jsonl'\n",
    "    sys_prompt = sys_prompt_template.format(topic=topic) \n",
    "\n",
    "    sample_questions = load_jsonl_file(file_path)\n",
    "    model = GPTModel(system_prompt=sys_prompt, model_name='gpt-4o')\n",
    "\n",
    "    prompt =f'Example questions:{sample_questions}\\n\\n'\n",
    "    prompt += \"Give your reasoning, then output the list of criteria in a python list. Each criterion should be 2-5 words.\"\n",
    "    prompt += f\"\"\"\n",
    "    1. Orthogonality: The criteria should be independent of each other.\n",
    "    2. Comprehensiveness: All criteria combined should cover the entire field of {topic}.\n",
    "    3. Relevance: The criteria should be relevant to the field of {topic} and the questions provided.\n",
    "    4. Clarity: The criteria should be clear and easy to understand.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt += \"\"\"\n",
    "        Use the following JSON formatting:\n",
    "        {{\n",
    "            \"reasoning\": \"Your reasoning here.\",\n",
    "            \"criteria\": [\n",
    "                \"criterion1\",\n",
    "                \"criterion2\",\n",
    "                \"criterion3\",\n",
    "                \"criterion4\",\n",
    "                \"criterion5\"\n",
    "            ]\n",
    "        }}\n",
    "    \"\"\"\n",
    "\n",
    "    output = model(prompt, use_json=True)\n",
    "\n",
    "    all_criteria[topic] = output[\"criteria\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Analyzing Financial Reports': ['Revenue Analysis',\n",
       "  'Expense Evaluation',\n",
       "  'Debt Assessment',\n",
       "  'Investment Impact',\n",
       "  'Strategic Insights']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to meta/0_criteria.json\n",
    "# read, append, write\n",
    "try:\n",
    "    with open(f'datasets/{meta}/0_criteria.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        data.update(all_criteria)\n",
    "        all_criteria = data\n",
    "except:\n",
    "    pass\n",
    "\n",
    "with open(f'datasets/{meta}/0_criteria.json', 'w') as f:\n",
    "    json.dump(all_criteria, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"your parameter\": \"As an AI language model, I don't have parameters in the same way a traditional software application might. However, I operate based on a vast dataset and complex algorithms to generate responses.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from core.models import GPTModel\n",
    "model = GPTModel(system_prompt=\"You are a helpful assistant.\", model_name=\"gpt-4o\")\n",
    "# print(model(\"hello!\"))\n",
    "rslt = (model('How many parameters do you have? respond in json: {{\"your parameter\": \"value, whatever you want here\"}}'))\n",
    "print(rslt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
