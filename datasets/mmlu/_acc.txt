abstract_algebra
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.25, 0.375, 0.5, 0.375, 0.5, 0.43333333333333335]	Oracle: [0.75, 0.625, 0.5, 0.625, 0.5, 0.5666666666666667]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.125, 0.25, 0.0, 0.125, 0.25, 0.3333333333333333]	Oracle: [0.875, 0.75, 1.0, 0.875, 0.75, 0.6666666666666667]
	Llama-2-13b-chat-hf	Accuracy: [0.25, 0.5, 0.125, 0.375, 0.125, 0.26666666666666666]	Oracle: [0.75, 0.5, 0.875, 0.625, 0.875, 0.7333333333333334]
	Llama-2-70b-chat-hf	Accuracy: [0.125, 0.25, 0.25, 0.375, 0.25, 0.36666666666666664]	Oracle: [0.875, 0.75, 0.75, 0.625, 0.75, 0.6333333333333333]
astronomy
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.875, 0.5, 0.875, 0.75, 0.875, 0.8333333333333334]	Oracle: [0.875, 0.5, 0.875, 0.75, 0.875, 0.8333333333333334]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.75, 0.375, 0.875, 0.625, 0.625, 0.6166666666666667]	Oracle: [0.75, 0.625, 0.875, 0.625, 0.625, 0.6166666666666667]
	Llama-2-13b-chat-hf	Accuracy: [1.0, 0.5, 0.875, 0.75, 0.625, 0.6166666666666667]	Oracle: [1.0, 0.5, 0.875, 0.75, 0.625, 0.6166666666666667]
	Llama-2-70b-chat-hf	Accuracy: [0.625, 0.625, 0.625, 0.625, 0.625, 0.6833333333333333]	Oracle: [0.625, 0.625, 0.625, 0.625, 0.625, 0.6833333333333333]
college_biology
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [1.0, 1.0, 0.75, 0.75, 0.5, 0.8]	Oracle: [1.0, 1.0, 0.75, 0.75, 0.5, 0.8]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.625, 0.75, 0.5, 0.75, 0.5, 0.6333333333333333]	Oracle: [0.625, 0.75, 0.5, 0.75, 0.5, 0.6333333333333333]
	Llama-2-13b-chat-hf	Accuracy: [0.75, 0.375, 0.75, 0.75, 0.375, 0.6]	Oracle: [0.75, 0.625, 0.75, 0.75, 0.625, 0.6]
	Llama-2-70b-chat-hf	Accuracy: [0.625, 0.75, 0.625, 0.625, 0.625, 0.6666666666666666]	Oracle: [0.625, 0.75, 0.625, 0.625, 0.625, 0.6666666666666666]
college_chemistry
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.375, 0.5, 0.25, 0.375, 0.5, 0.48333333333333334]	Oracle: [0.625, 0.5, 0.75, 0.625, 0.5, 0.5166666666666666]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.25, 0.375, 0.5, 0.25, 0.375, 0.3333333333333333]	Oracle: [0.75, 0.625, 0.5, 0.75, 0.625, 0.6666666666666667]
	Llama-2-13b-chat-hf	Accuracy: [0.25, 0.25, 0.25, 0.0, 0.5, 0.35]	Oracle: [0.75, 0.75, 0.75, 1.0, 0.5, 0.65]
	Llama-2-70b-chat-hf	Accuracy: [0.25, 0.375, 0.5, 0.375, 0.5, 0.4]	Oracle: [0.75, 0.625, 0.5, 0.625, 0.5, 0.6]
college_computer_science
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.375, 0.75, 0.625, 0.75, 0.625, 0.65]	Oracle: [0.625, 0.75, 0.625, 0.75, 0.625, 0.65]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.625, 0.375, 0.5, 0.5, 0.125, 0.55]	Oracle: [0.625, 0.625, 0.5, 0.5, 0.875, 0.55]
	Llama-2-13b-chat-hf	Accuracy: [0.5, 0.5, 0.375, 0.25, 0.375, 0.43333333333333335]	Oracle: [0.5, 0.5, 0.625, 0.75, 0.625, 0.5666666666666667]
	Llama-2-70b-chat-hf	Accuracy: [0.625, 0.625, 0.25, 0.375, 0.75, 0.45]	Oracle: [0.625, 0.625, 0.75, 0.625, 0.75, 0.55]
college_mathematics
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.375, 0.25, 0.5, 0.625, 0.25, 0.31666666666666665]	Oracle: [0.625, 0.75, 0.5, 0.625, 0.75, 0.6833333333333333]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.0, 0.25, 0.25, 0.375, 0.375, 0.2]	Oracle: [1.0, 0.75, 0.75, 0.625, 0.625, 0.8]
	Llama-2-13b-chat-hf	Accuracy: [0.25, 0.375, 0.25, 0.125, 0.125, 0.2833333333333333]	Oracle: [0.75, 0.625, 0.75, 0.875, 0.875, 0.7166666666666667]
	Llama-2-70b-chat-hf	Accuracy: [0.375, 0.25, 0.25, 0.25, 0.5, 0.25]	Oracle: [0.625, 0.75, 0.75, 0.75, 0.5, 0.75]
college_physics
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.875, 0.375, 0.5, 0.375, 0.75, 0.43333333333333335]	Oracle: [0.875, 0.625, 0.5, 0.625, 0.75, 0.5666666666666667]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.5, 0.125, 0.25, 0.625, 0.5, 0.3333333333333333]	Oracle: [0.5, 0.875, 0.75, 0.625, 0.5, 0.6666666666666667]
	Llama-2-13b-chat-hf	Accuracy: [0.375, 0.25, 0.125, 0.75, 0.5, 0.23333333333333334]	Oracle: [0.625, 0.75, 0.875, 0.75, 0.5, 0.7666666666666666]
	Llama-2-70b-chat-hf	Accuracy: [0.5, 0.125, 0.125, 0.625, 0.5, 0.31666666666666665]	Oracle: [0.5, 0.875, 0.875, 0.625, 0.5, 0.6833333333333333]
computer_security
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [1.0, 0.875, 0.75, 0.875, 0.75, 0.7833333333333333]	Oracle: [1.0, 0.875, 0.75, 0.875, 0.75, 0.7833333333333333]
	Mistral-7B-Instruct-v0.2	Accuracy: [1.0, 0.875, 0.75, 0.625, 0.625, 0.65]	Oracle: [1.0, 0.875, 0.75, 0.625, 0.625, 0.65]
	Llama-2-13b-chat-hf	Accuracy: [0.875, 0.75, 0.875, 0.75, 0.5, 0.65]	Oracle: [0.875, 0.75, 0.875, 0.75, 0.5, 0.65]
	Llama-2-70b-chat-hf	Accuracy: [0.875, 0.75, 1.0, 0.625, 0.375, 0.7333333333333333]	Oracle: [0.875, 0.75, 1.0, 0.625, 0.625, 0.7333333333333333]
elementary_mathematics
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.75, 0.75, 0.75, 0.875, 0.75, 0.75]	Oracle: [0.75, 0.75, 0.75, 0.875, 0.75, 0.75]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.5, 0.375, 0.75, 0.75, 0.5, 0.5166666666666667]	Oracle: [0.5, 0.625, 0.75, 0.75, 0.5, 0.5166666666666667]
	Llama-2-13b-chat-hf	Accuracy: [0.25, 0.125, 0.125, 0.25, 0.25, 0.43333333333333335]	Oracle: [0.75, 0.875, 0.875, 0.75, 0.75, 0.5666666666666667]
	Llama-2-70b-chat-hf	Accuracy: [0.875, 0.5, 0.75, 0.875, 0.5, 0.6]	Oracle: [0.875, 0.5, 0.75, 0.875, 0.5, 0.6]
global_facts
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.5, 0.5, 0.625, 0.375, 0.375, 0.4166666666666667]	Oracle: [0.5, 0.5, 0.625, 0.625, 0.625, 0.5833333333333333]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.25, 0.125, 0.25, 0.375, 0.375, 0.25]	Oracle: [0.75, 0.875, 0.75, 0.625, 0.625, 0.75]
	Llama-2-13b-chat-hf	Accuracy: [0.25, 0.125, 0.25, 0.625, 0.5, 0.5333333333333333]	Oracle: [0.75, 0.875, 0.75, 0.625, 0.5, 0.5333333333333333]
	Llama-2-70b-chat-hf	Accuracy: [0.125, 0.5, 0.5, 0.625, 0.5, 0.5166666666666667]	Oracle: [0.875, 0.5, 0.5, 0.625, 0.5, 0.5166666666666667]
high_school_biology
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.625, 0.75, 0.5, 0.875, 1.0, 0.8666666666666667]	Oracle: [0.625, 0.75, 0.5, 0.875, 1.0, 0.8666666666666667]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.375, 0.625, 0.375, 0.75, 0.875, 0.7666666666666667]	Oracle: [0.625, 0.625, 0.625, 0.75, 0.875, 0.7666666666666667]
	Llama-2-13b-chat-hf	Accuracy: [0.25, 0.375, 0.125, 0.625, 0.625, 0.6333333333333333]	Oracle: [0.75, 0.625, 0.875, 0.625, 0.625, 0.6333333333333333]
	Llama-2-70b-chat-hf	Accuracy: [0.375, 0.625, 0.5, 0.875, 0.75, 0.75]	Oracle: [0.625, 0.625, 0.5, 0.875, 0.75, 0.75]
high_school_chemistry
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.5, 0.75, 0.625, 0.875, 0.25, 0.6666666666666666]	Oracle: [0.5, 0.75, 0.625, 0.875, 0.75, 0.6666666666666666]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.375, 0.375, 0.375, 0.25, 0.25, 0.4166666666666667]	Oracle: [0.625, 0.625, 0.625, 0.75, 0.75, 0.5833333333333333]
	Llama-2-13b-chat-hf	Accuracy: [0.75, 0.375, 0.25, 0.5, 0.125, 0.35]	Oracle: [0.75, 0.625, 0.75, 0.5, 0.875, 0.65]
	Llama-2-70b-chat-hf	Accuracy: [0.5, 0.625, 0.375, 0.375, 0.125, 0.4]	Oracle: [0.5, 0.625, 0.625, 0.625, 0.875, 0.6]
high_school_computer_science
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.75, 1.0, 0.75, 0.75, 0.5, 0.75]	Oracle: [0.75, 1.0, 0.75, 0.75, 0.5, 0.75]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.625, 0.5, 0.25, 0.625, 0.625, 0.6833333333333333]	Oracle: [0.625, 0.5, 0.75, 0.625, 0.625, 0.6833333333333333]
	Llama-2-13b-chat-hf	Accuracy: [0.75, 0.5, 0.5, 0.625, 0.375, 0.6666666666666666]	Oracle: [0.75, 0.5, 0.5, 0.625, 0.625, 0.6666666666666666]
	Llama-2-70b-chat-hf	Accuracy: [0.75, 0.5, 0.625, 0.625, 0.625, 0.7333333333333333]	Oracle: [0.75, 0.5, 0.625, 0.625, 0.625, 0.7333333333333333]
high_school_mathematics
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.5, 0.375, 0.25, 0.125, 0.25, 0.4]	Oracle: [0.5, 0.625, 0.75, 0.875, 0.75, 0.6]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.375, 0.5, 0.125, 0.375, 0.125, 0.3333333333333333]	Oracle: [0.625, 0.5, 0.875, 0.625, 0.875, 0.6666666666666667]
	Llama-2-13b-chat-hf	Accuracy: [0.125, 0.25, 0.125, 0.125, 0.375, 0.23333333333333334]	Oracle: [0.875, 0.75, 0.875, 0.875, 0.625, 0.7666666666666666]
	Llama-2-70b-chat-hf	Accuracy: [0.625, 0.5, 0.375, 0.125, 0.125, 0.3]	Oracle: [0.625, 0.5, 0.625, 0.875, 0.875, 0.7]
high_school_physics
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.625, 0.25, 0.5, 0.625, 0.75, 0.5666666666666667]	Oracle: [0.625, 0.75, 0.5, 0.625, 0.75, 0.5666666666666667]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.375, 0.25, 0.25, 0.375, 0.5, 0.3]	Oracle: [0.625, 0.75, 0.75, 0.625, 0.5, 0.7]
	Llama-2-13b-chat-hf	Accuracy: [0.375, 0.125, 0.5, 0.25, 0.625, 0.26666666666666666]	Oracle: [0.625, 0.875, 0.5, 0.75, 0.625, 0.7333333333333334]
	Llama-2-70b-chat-hf	Accuracy: [0.75, 0.375, 0.375, 0.625, 0.625, 0.45]	Oracle: [0.75, 0.625, 0.625, 0.625, 0.625, 0.55]
high_school_statistics
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.5, 0.75, 0.375, 0.875, 0.5, 0.5166666666666667]	Oracle: [0.5, 0.75, 0.625, 0.875, 0.5, 0.5166666666666667]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.625, 0.625, 0.375, 0.5, 0.25, 0.4166666666666667]	Oracle: [0.625, 0.625, 0.625, 0.5, 0.75, 0.5833333333333333]
	Llama-2-13b-chat-hf	Accuracy: [0.375, 0.625, 0.25, 0.25, 0.375, 0.4]	Oracle: [0.625, 0.625, 0.75, 0.75, 0.625, 0.6]
	Llama-2-70b-chat-hf	Accuracy: [0.25, 0.875, 0.375, 0.25, 0.375, 0.31666666666666665]	Oracle: [0.75, 0.875, 0.625, 0.75, 0.625, 0.6833333333333333]
human_aging
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.625, 0.625, 1.0, 0.625, 0.875, 0.6833333333333333]	Oracle: [0.625, 0.625, 1.0, 0.625, 0.875, 0.6833333333333333]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.625, 0.625, 0.5, 0.75, 0.625, 0.6166666666666667]	Oracle: [0.625, 0.625, 0.5, 0.75, 0.625, 0.6166666666666667]
	Llama-2-13b-chat-hf	Accuracy: [0.75, 0.375, 0.375, 0.625, 0.625, 0.6]	Oracle: [0.75, 0.625, 0.625, 0.625, 0.625, 0.6]
	Llama-2-70b-chat-hf	Accuracy: [0.5, 0.5, 0.75, 0.75, 0.5, 0.65]	Oracle: [0.5, 0.5, 0.75, 0.75, 0.5, 0.65]
human_sexuality
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.75, 0.625, 0.5, 0.875, 0.625, 0.8833333333333333]	Oracle: [0.75, 0.625, 0.5, 0.875, 0.625, 0.8833333333333333]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.625, 0.375, 0.375, 0.875, 0.5, 0.7833333333333333]	Oracle: [0.625, 0.625, 0.625, 0.875, 0.5, 0.7833333333333333]
	Llama-2-13b-chat-hf	Accuracy: [0.5, 0.625, 0.375, 0.75, 0.625, 0.6166666666666667]	Oracle: [0.5, 0.625, 0.625, 0.75, 0.625, 0.6166666666666667]
	Llama-2-70b-chat-hf	Accuracy: [0.625, 0.375, 0.625, 0.625, 1.0, 0.7666666666666667]	Oracle: [0.625, 0.625, 0.625, 0.625, 1.0, 0.7666666666666667]
miscellaneous
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.75, 0.75, 0.875, 0.875, 0.875, 0.9166666666666666]	Oracle: [0.75, 0.75, 0.875, 0.875, 0.875, 0.9166666666666666]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.5, 0.625, 0.875, 0.75, 0.875, 0.8]	Oracle: [0.5, 0.625, 0.875, 0.75, 0.875, 0.8]
	Llama-2-13b-chat-hf	Accuracy: [1.0, 0.625, 0.75, 0.875, 0.875, 0.7666666666666667]	Oracle: [1.0, 0.625, 0.75, 0.875, 0.875, 0.7666666666666667]
	Llama-2-70b-chat-hf	Accuracy: [0.75, 0.75, 0.875, 0.875, 0.875, 0.7833333333333333]	Oracle: [0.75, 0.75, 0.875, 0.875, 0.875, 0.7833333333333333]
high_school_world_history
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.875, 0.75, 0.875, 0.75, 0.875, 0.8]	Oracle: [0.875, 0.75, 0.875, 0.75, 0.875, 0.8]
	Mistral-7B-Instruct-v0.2	Accuracy: [1.0, 0.75, 0.875, 0.625, 1.0, 0.6666666666666666]	Oracle: [1.0, 0.75, 0.875, 0.625, 1.0, 0.6666666666666666]
	Llama-2-13b-chat-hf	Accuracy: [0.625, 0.875, 0.625, 0.375, 0.75, 0.5833333333333334]	Oracle: [0.625, 0.875, 0.625, 0.625, 0.75, 0.5833333333333334]
	Llama-2-70b-chat-hf	Accuracy: [0.75, 0.625, 0.875, 0.75, 0.75, 0.7333333333333333]	Oracle: [0.75, 0.625, 0.875, 0.75, 0.75, 0.7333333333333333]
machine_learning
	Mixtral-8x7B-Instruct-v0.1	Accuracy: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5833333333333334]	Oracle: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5833333333333334]
	Mistral-7B-Instruct-v0.2	Accuracy: [0.375, 0.25, 0.125, 0.25, 0.5, 0.43333333333333335]	Oracle: [0.625, 0.75, 0.875, 0.75, 0.5, 0.5666666666666667]
	Llama-2-13b-chat-hf	Accuracy: [0.375, 0.125, 0.125, 0.0, 0.25, 0.31666666666666665]	Oracle: [0.625, 0.875, 0.875, 1.0, 0.75, 0.6833333333333333]
	Llama-2-70b-chat-hf	Accuracy: [0.5, 0.5, 0.0, 0.25, 0.625, 0.4]	Oracle: [0.5, 0.5, 1.0, 0.75, 0.625, 0.6]
